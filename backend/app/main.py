"""
Backend API entrypoints for ingesting and querying real-time system metrics.

This module implements the Phase-1 data path for the observability platform:

1) The C++ agent posts metric snapshots to `POST /ingest/metrics`.
2) The backend stores snapshots in Redis as a timestamp-sorted timeline.
3) Clients query recent data through `GET /api/metrics/recent`.

Design goals:
- Keep writes and reads lightweight for near-real-time operation.
- Retain only a rolling time window (default: last 5 minutes).
- Avoid hard dependency on local filesystem/database for Phase 1.

Redis data model:
- Key: configured by `REDIS_METRICS_KEY` (default: `metrics:timeline`)
- Type: Sorted Set (ZSET)
- Member: full JSON payload (serialized MetricsPayload)
- Score: payload timestamp (epoch seconds)

Why a ZSET:
- Efficient append-like inserts with timestamp score (`ZADD`)
- Efficient range queries for time windows (`ZRANGEBYSCORE`)
- Efficient pruning of old points (`ZREMRANGEBYSCORE`)

Retention policy:
- On each ingest, entries older than `RETENTION_SECONDS` are removed.
- The Redis key TTL is refreshed to `RETENTION_SECONDS * 2` so stale keys
    eventually disappear if ingestion stops.

Error handling strategy:
- Redis availability errors are surfaced as HTTP 503 so callers can retry.
- Health endpoint reports degraded state instead of throwing when Redis is down.
- Individual malformed records during read are skipped defensively.
"""

import json
from datetime import datetime, timedelta, timezone
from typing import List

from fastapi import HTTPException
from redis import Redis
from redis.exceptions import RedisError

from .declarations import (
        METRICS_KEY,
        REDIS_DB,
        REDIS_HOST,
        REDIS_PORT,
        RETENTION_SECONDS,
        MetricsPayload,
        app,
)


def get_redis() -> Redis:
        """
        Create and return a Redis client bound to configured host/port/database.

        Notes:
        - `decode_responses=True` ensures Redis returns `str` values instead of
            raw bytes, simplifying JSON parsing and response modeling.
        - Client construction is intentionally lightweight and done per request path;
            Redis-py internally manages socket connections.
        """
        return Redis(host=REDIS_HOST, port=REDIS_PORT, db=REDIS_DB, decode_responses=True)


@app.get("/health")
def health_check() -> dict:
        """
        Return service health with Redis connectivity status.

        Behavior:
        - If Redis responds to `PING`, returns `{"status": "ok", "redis": "connected"}`.
        - If Redis is unreachable/unavailable, returns
            `{"status": "degraded", "redis": "disconnected"}`.

        Rationale:
        - This endpoint is intended for liveness/readiness checks and operational
            dashboards. It intentionally avoids raising errors for degraded mode so
            health pollers can observe state transitions consistently.
        """
        try:
                client = get_redis()
                client.ping()
                return {"status": "ok", "redis": "connected"}
        except RedisError:
                return {"status": "degraded", "redis": "disconnected"}


@app.post("/ingest/metrics")
def ingest_metrics(payload: MetricsPayload) -> dict:
        """
        Ingest one metrics snapshot and maintain rolling-window retention.

        Request body:
        - `MetricsPayload` object generated by the agent, containing at least:
            timestamp, total CPU percentage, and top process list.

        Write path:
        - Compute minimum valid timestamp for the configured retention window.
        - Serialize payload once and use Redis pipeline for batched operations:
            1) `ZADD` insert current record using payload timestamp as score.
            2) `ZREMRANGEBYSCORE` prune records older than retention window.
            3) `EXPIRE` refresh key TTL to prevent unbounded stale key lifetime.

        Atomicity and performance:
        - The Redis pipeline reduces round-trips and keeps operations grouped.
            (Pipeline here is batching, not a Redis transaction.)

        Failure mode:
        - Any Redis error becomes HTTP 503 (`service unavailable`) so upstream
            senders can retry with backoff.

        Returns:
        - Acceptance acknowledgment including the ingested timestamp.
        """
        now = datetime.now(timezone.utc)
        min_ts = int((now - timedelta(seconds=RETENTION_SECONDS)).timestamp())

        try:
                client = get_redis()
                serialized = payload.model_dump_json()

                pipe = client.pipeline()
                pipe.zadd(METRICS_KEY, {serialized: payload.timestamp})
                pipe.zremrangebyscore(METRICS_KEY, "-inf", min_ts)
                pipe.expire(METRICS_KEY, RETENTION_SECONDS * 2)
                pipe.execute()
        except RedisError as ex:
                raise HTTPException(status_code=503, detail=f"Redis unavailable: {str(ex)}") from ex

        return {"status": "accepted", "timestamp": payload.timestamp}


@app.get("/api/metrics/recent", response_model=List[MetricsPayload])
def get_recent_metrics() -> List[MetricsPayload]:
        """
        Fetch metrics retained within the active rolling window.

        Query behavior:
        - Computes lower-bound timestamp as `now - RETENTION_SECONDS`.
        - Reads sorted-set members with score >= lower bound via `ZRANGEBYSCORE`.

        Parsing behavior:
        - Each Redis item is parsed as `MetricsPayload` JSON.
        - Malformed entries are skipped instead of failing the whole request,
            preserving API availability when partial corruption exists.

        Response:
        - Ordered list of `MetricsPayload` entries suitable for near-real-time
            charting and lightweight analytics.

        Failure mode:
        - Redis access failures are converted to HTTP 503.
        """
        now = datetime.now(timezone.utc)
        min_ts = int((now - timedelta(seconds=RETENTION_SECONDS)).timestamp())

        try:
                client = get_redis()
                data = client.zrangebyscore(METRICS_KEY, min_ts, "+inf")
        except RedisError as ex:
                raise HTTPException(status_code=503, detail=f"Redis unavailable: {str(ex)}") from ex

        parsed: List[MetricsPayload] = []
        for item in data:
                try:
                        parsed.append(MetricsPayload.model_validate_json(item))
                except (ValueError, json.JSONDecodeError):
                        continue

        return parsed
